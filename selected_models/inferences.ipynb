{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69c01ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.3.1\n",
      "TorchVision: 0.18.1\n",
      "CUDA available: False\n",
      "Pillow OK\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "from PIL import Image\n",
    "\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"TorchVision:\", torchvision.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Pillow OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc3beb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Classes (8): ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'scc', 'vasc']\n",
      "‚úÖ Model loaded successfully (CPU)\n",
      "\n",
      "üñºÔ∏è Inference Result\n",
      "Image      : ISIC_0000032.jpg\n",
      "Prediction : nv\n",
      "Confidence : 0.8777\n",
      "Latency    : 35.25 ms\n",
      "\n",
      "üîù Top-K:\n",
      " 1. nv (0.8777)\n",
      " 2. mel (0.0576)\n",
      " 3. akiec (0.0163)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üîπ CPU-ONLY Single Image Inference (EfficientNet-B2)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.models import efficientnet_b2\n",
    "from PIL import Image\n",
    "\n",
    "# ---------------- HARD CPU LOCK ----------------\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "torch.set_num_threads(max(1, os.cpu_count() // 2))\n",
    "\n",
    "# ---------------- Paths ----------------\n",
    "BASE_DIR = r\"D:\\mymodel\\selected_models\"\n",
    "MODEL_PATH = os.path.join(BASE_DIR, \"best_model_smart_combo_v2.pth\")\n",
    "CLASSES_PATH = os.path.join(BASE_DIR, \"classes.json\")\n",
    "\n",
    "IMAGE_PATH = r\"D:\\ISIC-images\\ISIC_0000032.jpg\"\n",
    "\n",
    "# ---------------- Params ----------------\n",
    "resolution = 260\n",
    "top_k = 3\n",
    "dropout_decoder = 0.3   # üîë MUST MATCH TRAINING\n",
    "\n",
    "# ---------------- Resize + Pad ----------------\n",
    "class ResizeAndPad:\n",
    "    def __init__(self, output_size, fill=0):\n",
    "        self.output_size = output_size\n",
    "        self.fill = fill\n",
    "\n",
    "    def __call__(self, img):\n",
    "        w, h = img.size\n",
    "        ratio = min(self.output_size / w, self.output_size / h)\n",
    "        new_w, new_h = int(w * ratio), int(h * ratio)\n",
    "        img = transforms.functional.resize(img, (new_h, new_w), antialias=True)\n",
    "        canvas = Image.new(\"RGB\", (self.output_size, self.output_size), self.fill)\n",
    "        canvas.paste(\n",
    "            img,\n",
    "            ((self.output_size - new_w) // 2,\n",
    "             (self.output_size - new_h) // 2)\n",
    "        )\n",
    "        return canvas\n",
    "\n",
    "# ---------------- Transforms ----------------\n",
    "infer_tf = transforms.Compose([\n",
    "    ResizeAndPad(resolution),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# ---------------- Model ----------------\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, encoder, num_classes, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 3, resolution, resolution)\n",
    "            out_features = self.encoder(dummy).shape[1]\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(dropout),          # üîë REQUIRED\n",
    "            nn.Linear(out_features, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.head(self.encoder(x))\n",
    "\n",
    "# ---------------- Load Classes ----------------\n",
    "with open(CLASSES_PATH, \"r\") as f:\n",
    "    classes = json.load(f)\n",
    "\n",
    "num_classes = len(classes)\n",
    "print(f\"üì¶ Classes ({num_classes}): {classes}\")\n",
    "\n",
    "# ---------------- Load Model ----------------\n",
    "backbone = efficientnet_b2(weights=None)\n",
    "encoder = nn.Sequential(*backbone.features)\n",
    "model = SimpleClassifier(encoder, num_classes, dropout=dropout_decoder)\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=\"cpu\"))\n",
    "model.eval()\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully (CPU)\")\n",
    "\n",
    "# ---------------- Inference ----------------\n",
    "img = Image.open(IMAGE_PATH).convert(\"RGB\")\n",
    "x = infer_tf(img).unsqueeze(0)\n",
    "\n",
    "start = time.perf_counter()\n",
    "logits = model(x)\n",
    "latency_ms = (time.perf_counter() - start) * 1000\n",
    "\n",
    "probs = torch.softmax(logits, dim=1)[0]\n",
    "conf, pred = torch.max(probs, dim=0)\n",
    "topk_conf, topk_idx = torch.topk(probs, top_k)\n",
    "\n",
    "# ---------------- Output ----------------\n",
    "print(\"\\nüñºÔ∏è Inference Result\")\n",
    "print(f\"Image      : {os.path.basename(IMAGE_PATH)}\")\n",
    "print(f\"Prediction : {classes[pred.item()]}\")\n",
    "print(f\"Confidence : {conf.item():.4f}\")\n",
    "print(f\"Latency    : {latency_ms:.2f} ms\")\n",
    "\n",
    "print(\"\\nüîù Top-K:\")\n",
    "for i in range(top_k):\n",
    "    print(f\" {i+1}. {classes[topk_idx[i].item()]} ({topk_conf[i].item():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ab3e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "effnet-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
